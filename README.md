# MarxLLM

### Welcome to this Open-source Repo!

This repository aims to guide enthusiasts and professionals in the world of Large Language Models (LLMs). Here, you will find resources and tools for:

1. **LLM Building**: Step-by-step guides and best practices to build your own Large Language Models from scratch. üõ†Ô∏è
2. **LLM Fine-tuning**: Techniques and methodologies to fine-tune pre-existing models to suit specific use-cases. üéØ
3. **Use-case Benchmarking**: Detailed processes and tools to benchmark LLMs across various use-cases, ensuring optimal performance. üìä

## Table of Contents

1. [Why This Repository?](#why-this-repository)
2. [Key Features](#key-features)
3. [Getting Started](#getting-started)
4. [Research Papers and Resources](#research-papers-and-resources)
   - [Large Language Models](#large-language-models)
     - [Research Papers](#research-papers)
     - [Blogs and Playlists](#blogs-and-playlists)
     - [Tools to build applications using LLMs](#tools-to-build-applications-using-llms)
   - [Retrieval Augmented Generation](#retrieval-augmented-generation)
5. [Contributing](#contributing)
6. [License](#license)
7. [Stay Updated](#stay-updated)

## Why This Repository?

Large Language Models are revolutionizing numerous fields, from natural language processing to AI-driven applications. However, navigating the complexities of building, fine-tuning, and benchmarking these models can be challenging. This open-source repository is designed to simplify these processes and provide a centralized hub for all related resources.

## Key Features

- **Comprehensive Guides**: Detailed documentation to help you get started with building and fine-tuning LLMs.
- **Benchmarking Tools**: Scripts and tools to benchmark the performance of your models across various use-cases.
- **Community Support**: Join our community of developers and researchers to share insights, ask questions, and collaborate on projects.

## Getting Started

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/Pragadesh-45/MarxLLM.git
   cd MarxLLM
   ```

## Why This Repository?

Large Language Models are revolutionizing numerous fields, from natural language processing to AI-driven applications. However, navigating the complexities of building, fine-tuning, and benchmarking these models can be challenging. This open-source repository is designed to simplify these processes and provide a centralized hub for all related resources.

## Key Features

- **Comprehensive Guides**: Detailed documentation to help you get started with building and fine-tuning LLMs.
- **Benchmarking Tools**: Scripts and tools to benchmark the performance of your models across various use-cases.
- **Community Support**: Join our community of developers and researchers to share insights, ask questions, and collaborate on projects.

## Getting Started

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/Pragadesh-45/MarxLLM.git
   cd MarxLLM
   ```

2. **Explore the Documentation**: Start with the [Getting Started Guide](https://github.com/Pragadesh-45/MarxLLM).

<!-- 3. **Join the Community**: Participate in discussions and find collaborators on our [Discord Server](link_to_discord_server). -->

## Research Papers and Resources üìö

To deepen your understanding of LLMs, we recommend the following research papers and resources:

1. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
2. [GPT-3: Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)
3. [Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping](https://arxiv.org/abs/2002.06305)
4. [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)


## Large Language Models

### Research Papers
1. [Attention is all you Need](https://arxiv.org/abs/1706.03762)
2. [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)
3. [The Llama 3 Herd of Models](https://arxiv.org/abs/2407.21783)

### Blogs and Playlists
1. [State of GPT by Andrej Karpathy](https://www.youtube.com/watch?v=bZQun8Y4L2A&t=332s)
2. [Introduction to Large Language Models by Andrej Karpathy](https://www.youtube.com/watch?v=zjkBMFhNj_g)
3. [A Hackers Guide to Large Language Models by Jeremy Howard](https://www.youtube.com/watch?v=jkrNMKz9pWU)
4. [Fine Tuning LLMs playlist by Krish Naik](https://youtube.com/playlist?list=PLZoTAELRMXVN9VbAx5I2VvloTtYmlApe3&si=LXpj6cc6dekxFKny)
5. [Understanding LLaMA-2 Architecture & its Ginormous Impact on GenAI by Kunal Sawarkar](https://medium.com/towards-generative-ai/understanding-llama-2-architecture-its-ginormous-impact-on-genai-e278cb81bd5c)
6. [Quantization in LLMs](https://symbl.ai/developers/blog/a-guide-to-quantization-in-llms/)

### Tools to build applications using LLMs 
1. [Langchain Playlist by Krish Naik](https://youtube.com/playlist?list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar&si=Up34S7nExf_wG4t-)
2. [Langchain Playlist by Codebasics](https://youtube.com/playlist?list=PLeo1K3hjS3uu0N_0W6giDXzZIcB07Ng_F&si=QMnZ33ofWa8wx3zt)
3. [Llamaindex playlist by Krish Naik](https://youtube.com/playlist?list=PLZoTAELRMXVNOWh1SDXt5NFujQMOt-CWy&si=I1zhino7NlwABIr4)

## Retrieval Augmented Generation
1. [IBM Research Blog: Retrieval-Augmented Generation (RAG)](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)
2. [Brad Sol: Retrieval-Augmented Generation (RAG) for LLMs - A Guide to Enhanced Accuracy and Trust](https://bradsol.com/resources/blogs/retrieval-augmented-generation-rag-for-llms-a-guide-to-enhanced-accuracy-and-trust/)
3. [Prompting Guide: Retrieval-Augmented Generation](https://www.promptingguide.ai/research/rag)
4. [srk.ai Blog: Retrieval-Augmented Generation, LLM Evaluation and LlamaIndex](https://srk.ai/blog/004-ai-llm-retrieval-eval-llamaindex)
5. [LlamaIndex Blog: Boosting RAG - Picking the Best Embedding & Reranker Models](https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83)
6. [Medium: Training and Decoding in RAG Models](https://medium.com/@nelson.miranda_40644/training-and-decoding-in-rag-models-bridging-knowledge-and-language-235be2bf4830)
7. [Galileo: Mastering RAG - How to Architect an Enterprise RAG System](https://www.rungalileo.io/blog/mastering-rag-how-to-architect-an-enterprise-rag-system)
8. [Microsoft Research Blog: GraphRAG - Unlocking LLM Discovery on Narrative Private Data](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)
9. [Pinecone: Vector Database Basics](https://www.pinecone.io/learn/vector-database/)
10. [Microsoft: GraphRAG Documentation](https://microsoft.github.io/graphrag/)
11. [Learn RAG From Scratch ‚Äì Python AI Tutorial from a LangChain Engineer](https://youtu.be/sVcwVQRHIc8?si=UE6fpSDnGXg1Izct)


## Contributing

We welcome contributions from the community! Whether it's improving documentation, adding new benchmarking scripts, or sharing your insights, your contributions are valuable. Please read our [Contributing Guidelines](link_to_contributing_guidelines) to get started.

## License

This project is licensed under the GPL-3.0 License - see the [LICENSE](https://github.com/Pragadesh-45/MarxLLM/blob/main/LICENSE) file for details.

## Stay Updated

Follow us on [GitHub](https://github.com/Pragadesh-45/MarxLLM) to stay updated on the latest developments and releases.
Feel free to add more research papers, resources, or links that you find useful. Let's build a comprehensive knowledge base together!
